{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-class notebook: 2024-01-10\n",
    "\n",
    "In this notebook, we will get familiar with the different definitions in descriptive statistics (how we describe a PDF short of actually spelling out the PDF). We will then look at a number of common distributions that you might encounter.\n",
    "\n",
    "This notebook is intended to support Chapter 3.2-3.3 of the textbook, and material is taken from the following scripts (from astroML):\n",
    "* https://github.com/astroML/astroML-notebooks/blob/main/chapter3/astroml_chapter3_Descriptive_Statistics.ipynb\n",
    "* https://github.com/astroML/astroML-notebooks/blob/main/chapter3/astroml_chapter3_Univariate_Distribution_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below, we'll show distributions with different skewness (top panel) and kurtosis (bottom panel). In the top panel, we'll plot a Gaussian, a modified Gaussian, and a log-normal distribution with $\\sigma = 1.2$. The modified Gaussian is a normal distribution multiplied by a Gram-Charlier series $ h(x) = N(\\mu,\\sigma)\\sum_{k=0}^\\infty a_k H_k(z)$ with $a_0 = 2$, $a_1 = 1$, and $a_2 = 0.5$. For the kurtosis panel, we'll plot a uniform, Laplace, cosine, and Gaussian distribution. \n",
    "\n",
    "\n",
    "We can find the values for skewness and kurtosis for each distribution by importing the desired distribution from`scipy.stats`. For example, we can call `from scipy.stats import uniform` and then call `uniform.stats(moments='sk')` to get the skewness and kurtosis for a uniform distribution. For the modified Gaussian however, we will hard-code $\\Sigma = -0.36.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, norm, laplace, cosine, lognorm\n",
    "\n",
    "uni = float(uniform.stats(moments = 'k'))\n",
    "lap = int(laplace.stats(moments = 'k'))\n",
    "cos = float(cosine.stats(moments = 'k'))\n",
    "log = float(lognorm.stats(1.2, moments = 's'))\n",
    "\n",
    "gauss = norm.stats(moments = 'sk')\n",
    "skew_gauss = int(gauss[0])\n",
    "kurt_gauss = int(gauss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(7.5, 10))\n",
    "fig.subplots_adjust(right=0.95, hspace=0.05, bottom=0.07, top=0.95)\n",
    "\n",
    "# First show distributions with different skeq\n",
    "ax = fig.add_subplot(211)\n",
    "x = np.linspace(-8, 8, 1000)\n",
    "N = stats.norm(0, 1)\n",
    "\n",
    "l1, = ax.plot(x, N.pdf(x), '-k',\n",
    "              label='Gaussian, $\\Sigma={}$'.format(skew_gauss))\n",
    "l2, = ax.plot(x, 0.5 * N.pdf(x) * (2 + x + 0.5 * (x * x - 1)),\n",
    "              '--k', label= 'mod. Gauss, $\\Sigma=-0.36$')\n",
    "l3, = ax.plot(x[499:], stats.lognorm(1.2).pdf(x[499:]), '-.k',\n",
    "              label='log normal, $\\Sigma={}$'.format(round(log,1)))\n",
    "\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(0, 0.7001)\n",
    "ax.set_ylabel('$p(x)$', fontsize = 12)\n",
    "ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "# trick to show multiple legends\n",
    "leg1 = ax.legend([l1], [l1.get_label()], loc=1, fontsize = 12)\n",
    "leg2 = ax.legend([l2, l3], (l2.get_label(), l3.get_label()), loc=2, fontsize = 12)\n",
    "ax.add_artist(leg1)\n",
    "ax.set_title('Skew $\\Sigma$ and Kurtosis $K$', fontsize = 16)\n",
    "\n",
    "# next show distributions with different kurtosis\n",
    "ax = fig.add_subplot(212)\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "l1, = ax.plot(x, stats.laplace(0, 1).pdf(x), '--k',\n",
    "              label='Laplace, K={}'.format(lap))\n",
    "l2, = ax.plot(x, stats.norm(0, 1).pdf(x), '-k',\n",
    "              label='Gaussian K={}'.format(kurt_gauss))\n",
    "l3, = ax.plot(x, stats.cosine(0, 1).pdf(x), '-.k',\n",
    "              label='Cosine, K=-0.59'.format(round(cos,2)))\n",
    "l4, = ax.plot(x, stats.uniform(-2, 4).pdf(x), ':k',\n",
    "              label='Uniform, K=-1.2'.format(uni))\n",
    "\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(0, 0.55)\n",
    "ax.set_xlabel('$x$', fontsize = 12)\n",
    "ax.set_ylabel('$p(x)$', fontsize = 12)\n",
    "\n",
    "# trick to show multiple legends\n",
    "leg1 = ax.legend((l1, l2), (l1.get_label(), l2.get_label()), loc=2, fontsize = 12)\n",
    "leg2 = ax.legend((l3, l4), (l3.get_label(), l4.get_label()), loc=1,fontsize = 12)\n",
    "ax.add_artist(leg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful NumPy and SciPy functions\n",
    "\n",
    "The cell below computes multiple statistical functions on a one-dimensional array **x**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "x = np.random.random(100) # 100 random numbers \n",
    "\n",
    "q25, q50, q75 = np.percentile(x, [25, 50, 75])\n",
    "mean = np.mean(x)\n",
    "median = np.median(x) \n",
    "variance = np.var(x) \n",
    "standard_deviation = np.std(x)\n",
    "skew = scipy.stats.skew(x)\n",
    "kurtosis = scipy.stats.kurtosis(x)\n",
    "mode = scipy.stats.mode(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-based estimates of descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncorrected = []\n",
    "corrected = []\n",
    "for x in range(1,5000):\n",
    "    samples = np.random.normal(loc=5.0, scale=1.0, size = 5)\n",
    "    uncorrected.append(np.std(samples, ddof=0))\n",
    "    corrected.append(np.std(samples, ddof=1))\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(15,6)   \n",
    "ax[0].hist(uncorrected);\n",
    "ax[1].hist(corrected);\n",
    "ax[0].text(1.65, 1200, f'mean = {np.mean(uncorrected):.2}',\n",
    "        bbox={'facecolor':'white', 'alpha':0.5, 'pad':1, 'boxstyle':\"round\"})\n",
    "ax[1].text(1.85, 1200, f'mean = {np.mean(corrected):.2}',\n",
    "        bbox={'facecolor':'white', 'alpha':0.5, 'pad':1, 'boxstyle':\"round\"})\n",
    "ax[0].set_title(\"Uncorrected Standard Deviations\");\n",
    "ax[1].set_title(\"Corrected Standard Deviations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty in our estimators $\\overline{x}$ and $s$\n",
    "\n",
    "When $N$ is large (at least ten or so), and if the variance of $h(x)$ is finite, we expect from the central limit theorem (in chapter 3.4) that $x$ and $s$ will be distributed around their values given by eqs. 1 and 2 according to Gaussian distributions with the widths (standard errors) equal to\n",
    "\n",
    "$$ \\sigma_{\\overline{x}} = \\frac{s}{\\sqrt{N}},$$\n",
    "\n",
    "which is called *the standard error of the mean*, and\n",
    "\n",
    "$$ \\sigma_s = \\frac{s}{\\sqrt{2(N-1)}} = \\frac{1}{\\sqrt{2}}\\sqrt{\\frac{N}{N-1}} \\sigma_\\overline{x},$$\n",
    " \n",
    "which is the *error of the standard deviation.*\n",
    "\n",
    "Note that for large $N$, the uncertainty of the location parameter is about 40% larger than the uncertainty of the scale parameter ($\\sigma_\\overline{x}$ $\\sim$ $\\sqrt{2}\\sigma_s$). Note also that for small $N$, $\\sigma_s$ is not much smaller than $s$ itself.\n",
    "\n",
    "### Example of standard deviation vs. standard error\n",
    "\n",
    "**Standard deviation**: Imagine we flip a coin 16 times; this will be one trial. As the number of trials goes to infinity, the number of heads flipped in one trial will yield a normal distribution with mean $\\mu$ = 8 and std $\\sigma$ = 2. No matter how many measurements we perform, the standard deviation will not reduce as its a property intrinsic to the nature of the coin.\n",
    "\n",
    "**Standard error**: The average number of heads in a 16 flip coin toss is eight since each side has a 50/50 chance of being landed on. With enough measurements, the error of that estimate of the mean number of heads can become arbitrarily small.\n",
    "\n",
    "Below is the distribution of a 16-flip coin toss for $N = 5000$ and $N = 15000$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(1,2) \n",
    "fig.set_size_inches(10,4)   \n",
    "np.random.seed(42)\n",
    "N = [5000, 15000]\n",
    "\n",
    "for m,k in enumerate (N):\n",
    "    y = np.random.binomial(n=16, p=0.5, size=k) # N trials of 16 flip toss\n",
    "    values = []\n",
    "    x = np.linspace(1,16, num = 16)\n",
    "    for i in range(1,17):\n",
    "        values.append(np.count_nonzero(y == i))\n",
    "    ax[m].bar(x,values)\n",
    "    print(f'Mean = {np.mean(y):.2}, Std = {np.std(y):.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "j = []\n",
    "for i in [3,30,100,1000]:\n",
    "    sample = np.random.binomial(n=16, p=0.5, size= i)\n",
    "    sample = round(sem(sample),2)\n",
    "    j.append(sample)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astroML import stats\n",
    "np.random.seed(0)\n",
    "x = np.random.normal(size=1000) # 1000 normally distributed points \n",
    "stats.sigmaG(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astroML import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import cauchy\n",
    "  \n",
    "normal = np.random.normal(loc=8.0, scale=1.0, size=100) # 100 samples from a Gaussian\n",
    "\n",
    "a = np.random.normal(loc=8.0, scale=1.0, size=95) #95 samples from a Gaussian\n",
    "b = cauchy.rvs(loc=8.0, scale=20, size=5) #5 samples from a Cauchy\n",
    "normal_with_outliers = np.concatenate([a, b]) # combine to create Gaussian with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['no outliers', 'with outliers']\n",
    "means = [np.mean(normal),np.mean(normal_with_outliers)]\n",
    "standard_deviations = [np.std(normal),np.std(normal_with_outliers)]\n",
    "medians = [np.median(normal), np.median(normal_with_outliers)]\n",
    "sigmaG = [stats.sigmaG(normal), stats.sigmaG(normal_with_outliers)]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(14,6)   \n",
    "rects1 = ax[0].bar(x - width/2, means, width, label='mean', color = 'steelblue')\n",
    "rects2 = ax[0].bar(x + width/2, standard_deviations, width, label='std', color = 'darkorange')\n",
    "rects3 = ax[1].bar(x - width/2, medians, width, label='median', color = 'olivedrab')\n",
    "rects4 = ax[1].bar(x + width/2, sigmaG, width, label='sigmaG', color = 'gold')\n",
    "\n",
    "titles = [\"means and std's\",\"medians and sigmaG's\"]\n",
    "rected = [(1,2),(3,4)]\n",
    "for i in [0,1]:\n",
    "    ax[i].set_ylabel('value')\n",
    "    ax[i].set_xticks(x);\n",
    "    ax[i].set_xticklabels(labels)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_title(titles[i])\n",
    "\n",
    "combined = means + standard_deviations + medians + sigmaG\n",
    "ax[1].set_ylim([0, np.max(combined)+0.5])\n",
    "\n",
    "ax[0].bar_label(rects1, padding=3)\n",
    "ax[0].bar_label(rects2, padding=3)\n",
    "ax[1].bar_label(rects3, padding=3)\n",
    "ax[1].bar_label(rects4, padding=3)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariable fuctions\n",
    "\n",
    "In the code below, we will first show the distributions themselves, and then show how you can calculate some of the descriptive statistics using the scipy in-built functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cauchy (Lorentzian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace (exponential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\chi^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student’s t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher’s F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astr340",
   "language": "python",
   "name": "astr340"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
