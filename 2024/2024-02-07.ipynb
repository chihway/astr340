{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-class notebook: 2024-02-07\n",
    "\n",
    "\n",
    "In this notebook, we look at different methods to look for structure in the data. We will use the SDSS Great Wall as an example to look at different Kernal Density Estimations (KDE), Gaussian Mixure Models (GMM) and hierarchical clustering. We will then briefly talk about correlation functions. \n",
    "\n",
    "This notebook is intended to support Chapter 6 of the textbook, and material is taken from the following scripts (from astroML):\n",
    "* https://github.com/astroML/astroML-notebooks/blob/main/chapter6/astroml_chapter6_Density_Estimation_for_SDSS_Great_Wall.ipynb\n",
    "* https://github.com/astroML/astroML_figures/blob/main/book_figures/chapter6/fig_great_wall_MST.py\n",
    "* https://github.com/astroML/astroML_figures/blob/main/book_figures/chapter6/fig_correlation_function.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Estimation for SDSS \"Great Wall\"\n",
    "\n",
    "This region is known as the \"SDSS Great Wall\", and contains an extended cluster of several thousand galaxies approximately 300Mpc (about 1 billion light years) from earth.  This shows the positions of over 8,000 galaxies projected to a 2D plane with Earth at the point (0, 0).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid on which to evaluate the results\n",
    "Nx = 50\n",
    "Ny = 125\n",
    "xmin, xmax = (-375, -175)\n",
    "ymin, ymax = (-300, 200)\n",
    "\n",
    "A = np.meshgrid(np.linspace(xmin, xmax, Nx), np.linspace(ymin, ymax, Ny))\n",
    "Xgrid = np.array((A[0].flatten(),A[1].flatten())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the great wall data\n",
    "\n",
    "from astroML.datasets import fetch_great_wall\n",
    "X = fetch_great_wall()\n",
    "print(len(X))\n",
    "\n",
    "# First plot: scatter the points\n",
    "ax1 = plt.subplot(111, aspect='equal')\n",
    "ax1.scatter(X[:, 1], X[:, 0], s=1, lw=0, c='k')\n",
    "ax1.text(0.95, 0.9, \"input\", ha='right', va='top',\n",
    "         transform=ax1.transAxes,\n",
    "         bbox=dict(boxstyle='round', ec='k', fc='w'))\n",
    "\n",
    "ax1.set_xlim(ymin, ymax - 0.01)\n",
    "ax1.set_ylim(xmin, xmax)\n",
    "    \n",
    "ax1.set_xlabel('$y$ (Mpc)')\n",
    "ax1.set_ylabel('$x$ (Mpc)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate KDE with Gaussian Kernel\n",
    "\n",
    "Use a *Gaussian kernel* to evaluate the kernel density. The function $K(u)$, a smooth function, represents the weight at a given point, which is normalized such that $\\int K(u)du = 1$.  \n",
    "The expression for Gaussian kernel is \n",
    "\n",
    "$$K(u) = \\frac{1}{ {2\\pi}^{\\frac{D}{2}} } e^{\\frac{-{u}^2}{2}}$$  \n",
    "\n",
    "where D is the number of dimensions of the parameter space and $u = d(x, x_i) /h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate Gaussian kernel\n",
    "# you can read the documentation here\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def estimate_kde(ker):\n",
    "    kde = KernelDensity(bandwidth=5, kernel=ker)\n",
    "    log_dens = kde.fit(X).score_samples(Xgrid) # compute log likelihood\n",
    "    dens = X.shape[0] * np.exp(log_dens).reshape((Ny, Nx))\n",
    "    return dens\n",
    "   \n",
    "dens1 = estimate_kde('gaussian')\n",
    "\n",
    "plt.imshow(dens1.T, origin='lower',\n",
    "               extent=(ymin, ymax, xmin, xmax), cmap=plt.cm.binary)\n",
    "\n",
    "plt.title('Gaussian (h=5)')\n",
    "plt.xlabel('$y$ (Mpc)')\n",
    "plt.ylabel('$x$ (Mpc)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log scale\n",
    "plt.imshow(dens1.T, origin='lower', norm=LogNorm(),\n",
    "               extent=(ymin, ymax, xmin, xmax), cmap=plt.cm.binary)\n",
    "\n",
    "plt.title('Gaussian (h=5)')\n",
    "\n",
    "plt.xlabel('$y$ (Mpc)')\n",
    "plt.ylabel('$x$ (Mpc)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate KDE with Top-hat Kernel\n",
    "Use a *top-hat (box) kernel* to evaluate the kernel density. The expression for top-hat kernel is \n",
    "\n",
    "$$f(z) = \\left\\{ \\begin{array}{rcl}\n",
    "\\frac{1}{V_{D}(1)} & \\mbox{if} & |u|\\leq1, \\\\\n",
    "0 & \\mbox{if} & |u|>1.\n",
    "\\end{array}\\right.$$  \n",
    "\n",
    "This kernel gives the most \"spread out\" estimation for each distribution freature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens2 = estimate_kde('tophat')\n",
    "\n",
    "plt.imshow(dens2.T, origin='lower',\n",
    "               extent=(ymin, ymax, xmin, xmax), cmap=plt.cm.binary)\n",
    "\n",
    "plt.title('Tophat (h=5)')\n",
    "\n",
    "plt.xlabel('$y$ (Mpc)')\n",
    "plt.ylabel('$x$ (Mpc)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate KDE with Exponential Kernel\n",
    "Use a *exponential kernel* to evaluate the kernel density. The expression for exponential kernel is \n",
    "\n",
    "$$K(u) = \\frac{1}{D!V_{D}(1)}e^{-|u|}.$$  \n",
    "\n",
    "where $V_D(r)$ is the volume of a D-dimensional hypersphere of radius r.  \n",
    "This kernel gives the \"sharpest\" estimation for each distribution feature.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens3 = estimate_kde('exponential')\n",
    "\n",
    "plt.imshow(dens3.T, origin='lower',\n",
    "               extent=(ymin, ymax, xmin, xmax), cmap=plt.cm.binary)\n",
    "\n",
    "plt.title('Exponential (h=5)')\n",
    "\n",
    "plt.xlabel('$y$ (Mpc)')\n",
    "plt.ylabel('$x$ (Mpc)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate density using K-Nearest-Neighbor Estimation\n",
    "Another estimator is the K-nearest-neighbor estimator, originally proposed by [Dressler et al. 1980](https://ui.adsabs.harvard.edu/abs/1980ApJ...236..351D/abstract) . In this method, the implied point density at an arbitrary position x is estimated as\n",
    "\n",
    "$$\\hat{f_K}(x) = \\frac{K}{V_D(d_K)}$$\n",
    "\n",
    "where $V_D$ is evaluated volume, and D is the problem dimensionality.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate K Neighbors Density with k = 5\n",
    "from astroML.density_estimation import KNeighborsDensity\n",
    "\n",
    "knn5 = KNeighborsDensity('bayesian', 5)\n",
    "dens_k5 = knn5.fit(X).eval(Xgrid).reshape((Ny, Nx))\n",
    "\n",
    "plt.imshow(dens_k5.T, origin='lower', #norm=LogNorm(), # show log\n",
    "               extent=(ymin, ymax, xmin, xmax), cmap=plt.cm.binary)\n",
    "\n",
    "plt.title('KNN (k=5)')\n",
    "\n",
    "plt.xlabel('$y$ (Mpc)')\n",
    "plt.ylabel('$x$ (Mpc)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# KNeighborsDensity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate K Neighbors Density with k = 40\n",
    "knn40 = KNeighborsDensity('bayesian', 40)\n",
    "dens_k40 = knn40.fit(X).eval(Xgrid).reshape((Ny, Nx))\n",
    "\n",
    "plt.imshow(dens_k40.T, origin='lower', #norm=LogNorm(), # show log\n",
    "               extent=(ymin, ymax, xmin, xmax), cmap=plt.cm.binary)\n",
    "\n",
    "plt.title('KNN (k=40)')\n",
    "\n",
    "plt.xlabel('$y$ (Mpc)')\n",
    "plt.ylabel('$x$ (Mpc)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Model\n",
    "GMM calculate the underlying pdf of a point as a sum of multi-dimensional Gaussians using the equation below\n",
    "\n",
    "$$\\rho(x) = Np(x) = N \\sum_{j=1}^{M} \\alpha_j \\mathcal{N}(\\mu_j, \\Sigma_j)$$\n",
    "\n",
    "where M is the number of Gaussians, $\\mu_j$ is the the location, and $\\Sigma_j$ is the covariance of a Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Calculate GMM\n",
    "def compute_GMM(n_clusters, max_iter=1000, tol=3, covariance_type='full'):\n",
    "    clf = GaussianMixture(n_clusters, covariance_type=covariance_type,\n",
    "                          max_iter=max_iter, tol=tol, random_state=0)\n",
    "    clf.fit(X)\n",
    "    print(\"converged:\", clf.converged_)\n",
    "    return clf\n",
    "\n",
    "clf = compute_GMM(n_clusters=200)\n",
    "log_dens = clf.score_samples(Xgrid).reshape(Ny, Nx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(np.exp(log_dens.T), origin='lower', #norm=LogNorm(), # show log\n",
    "               extent=(ymin, ymax, xmin, xmax), cmap=plt.cm.binary)\n",
    "\n",
    "plt.title('GMM (N=200)')\n",
    "\n",
    "plt.xlabel('$y$ (Mpc)')\n",
    "plt.ylabel('$x$ (Mpc)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a hierarchical tree (a Euclidean Minimum Spanning Tree, MST) of the data and use it to define clusters. We first show the dendrogram connecting them, then the clustering based on this dendrogram, created by removing the largest 10% of the graph edges, and keeping the remaining connected clusters with 30 or more members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph\n",
    "# see here: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.kneighbors_graph.html\n",
    "\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "# see here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csgraph.minimum_spanning_tree.html\n",
    "# A minimum spanning tree is a graph consisting of the subset of edges which together \n",
    "# connect all connected nodes, while minimizing the total sum of weights on the edges. \n",
    "# This is computed using the Kruskal algorithm.\n",
    "\n",
    "XX = np.random.random((100,2))\n",
    "G = kneighbors_graph(XX, n_neighbors=10, mode = 'distance')\n",
    "# only keep nearest 10 neighbors\n",
    "T = minimum_spanning_tree(G)\n",
    "\n",
    "# a graph is a sparse matrix, showing True if the element is within 2 distance, and 0 if not\n",
    "# X = [[0], [3], [1]]\n",
    "# >>> from sklearn.neighbors import kneighbors_graph\n",
    "# >>> A = kneighbors_graph(X, 2, mode='connectivity', include_self=True)\n",
    "# >>> A.toarray()\n",
    "# array([[1., 0., 1.],\n",
    "#        [0., 1., 1.],\n",
    "#        [1., 0., 1.]])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(G.toarray())\n",
    "plt.colorbar()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(T.toarray())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from astroML.clustering import HierarchicalClustering, get_graph_segments\n",
    "\n",
    "# Compute the MST clustering model\n",
    "n_neighbors = 10 # number of neighbors in the MST\n",
    "edge_cutoff = 0.9 # fraction of \"edges\" to keep, where an edge is one line segment in the MST\n",
    "cluster_cutoff = 10 # clusters must have <10 nodes\n",
    "model = HierarchicalClustering(n_neighbors=n_neighbors,\n",
    "                               edge_cutoff=edge_cutoff,\n",
    "                               min_cluster_size=cluster_cutoff)\n",
    "model.fit(X)\n",
    "print(\"max scale of cluster: %2g Mpc\" % np.percentile(model.full_tree_.data,100 * edge_cutoff))\n",
    "\n",
    "n_components = model.n_components_\n",
    "labels = model.labels_\n",
    "print(n_components, \"clusters\", labels.shape, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the x, y coordinates of the beginning and end of each line segment\n",
    "T_x, T_y = get_graph_segments(model.X_train_,\n",
    "                              model.full_tree_)\n",
    "# full tree\n",
    "\n",
    "T_trunc_x, T_trunc_y = get_graph_segments(model.X_train_,\n",
    "                                          model.cluster_graph_)\n",
    "# only keep clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a GaussianMixture to each individual cluster\n",
    "Nx = 50\n",
    "Ny = 125\n",
    "xmin, xmax = (-375, -175)\n",
    "ymin, ymax = (-300, 200)\n",
    "\n",
    "A = np.meshgrid(np.linspace(xmin, xmax, Nx), np.linspace(ymin, ymax, Ny))\n",
    "Xgrid = np.array((A[0].flatten(),A[1].flatten())).T\n",
    "\n",
    "density = np.zeros(Xgrid.shape[0])\n",
    "\n",
    "for i in range(n_components):\n",
    "    ind = (labels == i)\n",
    "    Npts = ind.sum()\n",
    "    Nclusters = min(12, Npts // 5)\n",
    "    gmm = GaussianMixture(Nclusters, random_state=0).fit(X[ind])\n",
    "    dens = np.exp(gmm.score_samples(Xgrid))\n",
    "    density += dens / dens.max()\n",
    "\n",
    "density = density.reshape((Ny, Nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 2.5))\n",
    "\n",
    "plt.plot(T_y, T_x, c='k', lw=0.5)\n",
    "\n",
    "plt.title('Full MST')\n",
    "plt.xlim(ymin, ymax)\n",
    "plt.ylim(xmin, xmax)\n",
    "\n",
    "plt.xlabel('$y$ (Mpc)')\n",
    "plt.ylabel('$x$ (Mpc)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.5, 3))\n",
    "\n",
    "plt.plot(T_trunc_y, T_trunc_x, c='k', lw=0.5)\n",
    "plt.imshow(density.T, origin='lower', cmap=plt.cm.hot_r,\n",
    "          extent=[ymin, ymax, xmin, xmax])\n",
    "\n",
    "plt.title('Clusters')\n",
    "plt.xlim(ymin, ymax)\n",
    "plt.ylim(xmin, xmax)\n",
    "\n",
    "plt.xlabel('$y$ (Mpc)')\n",
    "plt.ylabel('$x$ (Mpc)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Functions\n",
    "\n",
    "The two-point correlation function of SDSS spectroscopic galaxies in the range 0.08 < z < 0.12, with m < 17.7. This is the same sample for which the luminosity function is computed in figure 4.10. Errors are estimated using ten\n",
    "bootstrap samples. Dotted lines are added to guide the eye and correspond to a power law proportional to :math:`\\theta^{-0.8}`. Note that the red galaxies (left panel) are clustered more strongly than the blue galaxies (right panel).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from astroML.utils.decorators import pickle_results\n",
    "from astroML.datasets import fetch_sdss_specgals\n",
    "from astroML.correlation import bootstrap_two_point_angular\n",
    "# you can check out here to see how the two-point calculation is done with a KD tree\n",
    "# https://github.com/astroML/astroML/blob/main/astroML/correlation.py\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Get data and do some quality cuts\n",
    "data = fetch_sdss_specgals()\n",
    "m_max = 17.7\n",
    "\n",
    "# redshift and magnitude cuts\n",
    "data = data[data['z'] > 0.08]\n",
    "data = data[data['z'] < 0.12]\n",
    "data = data[data['petroMag_r'] < m_max]\n",
    "\n",
    "# RA/DEC cuts\n",
    "RAmin, RAmax = 140, 220\n",
    "DECmin, DECmax = 5, 45\n",
    "data = data[data['ra'] < RAmax]\n",
    "data = data[data['ra'] > RAmin]\n",
    "data = data[data['dec'] < DECmax]\n",
    "data = data[data['dec'] > DECmin]\n",
    "\n",
    "ur = data['modelMag_u'] - data['modelMag_r']\n",
    "flag_red = (ur > 2.22)\n",
    "flag_blue = ~flag_red\n",
    "\n",
    "data_red = data[flag_red]\n",
    "data_blue = data[flag_blue]\n",
    "\n",
    "print(\"data size:\")\n",
    "print(\"  red gals: \", len(data_red))\n",
    "print(\"  blue gals:\", len(data_blue))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Set up correlation function computation\n",
    "#  This calculation takes a long time with the bootstrap resampling,\n",
    "#  so we'll save the results.\n",
    "@pickle_results(\"correlation_functions.pkl\")\n",
    "def compute_results(Nbins=16, Nbootstraps=10,  method='landy-szalay', rseed=0):\n",
    "    np.random.seed(rseed)\n",
    "    bins = 10 ** np.linspace(np.log10(1 / 60.), np.log10(6), 16)\n",
    "\n",
    "    results = [bins]\n",
    "    for D in [data_red, data_blue]:\n",
    "        results += bootstrap_two_point_angular(D['ra'],\n",
    "                                               D['dec'],\n",
    "                                               bins=bins,\n",
    "                                               method=method,\n",
    "                                               Nbootstraps=Nbootstraps)\n",
    "\n",
    "    return results\n",
    "\n",
    "(bins, r_corr, r_corr_err, r_bootstraps,\n",
    " b_corr, b_corr_err, b_bootstraps) = compute_results()\n",
    "\n",
    "bin_centers = 0.5 * (bins[1:] + bins[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "corr = [r_corr, b_corr]\n",
    "corr_err = [r_corr_err, b_corr_err]\n",
    "bootstraps = [r_bootstraps, b_bootstraps]\n",
    "labels = ['$u-r > 2.22$\\n$N=%i$' % len(data_red),\n",
    "          '$u-r < 2.22$\\n$N=%i$' % len(data_blue)]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "\n",
    "for i in range(2):\n",
    "    ax = fig.add_subplot(121 + i, xscale='log', yscale='log')\n",
    "\n",
    "    ax.errorbar(bin_centers, corr[i], corr_err[i],\n",
    "                fmt='.k', ecolor='gray', lw=1)\n",
    "\n",
    "    t = np.array([0.01, 10])\n",
    "    ax.plot(t, 10 * (t / 0.01) ** -0.8, ':k', linewidth=1)\n",
    "\n",
    "    ax.text(0.95, 0.95, labels[i],\n",
    "            ha='right', va='top', transform=ax.transAxes)\n",
    "    ax.set_xlabel(r'$\\theta\\ (deg)$')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(r'$\\hat{w}(\\theta)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astr340",
   "language": "python",
   "name": "astr340"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
