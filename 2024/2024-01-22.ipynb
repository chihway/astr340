{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-class notebook: 2024-01-22\n",
    "\n",
    "In this notebook, we will look at some common usages of classical statistical inference. We first look at empirical estimates of error bars, then look at hypothesis testing and ways to compare distributions. \n",
    "\n",
    "This notebook is intended to support Chapter 4.5-4.9 of the textbook, and material is taken from the following scripts (from astroML):\n",
    "* https://github.com/astroML/astroML-notebooks/blob/main/chapter4/astroml_chapter4_Confidence_estimates.ipynb\n",
    "* https://github.com/astroML/astroML-notebooks/blob/main/chapter4/astroml_chapter4_Hypothesis_testing.ipynb\n",
    "* https://github.com/astroML/astroML-notebooks/blob/main/chapter4/astroml_chapter4_Comparison_of_distributions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence estimation: Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import norm\n",
    "from astroML.resample import bootstrap\n",
    "from astroML.stats import sigmaG\n",
    "\n",
    "m = 1000  # number of points\n",
    "n = 10000  # number of bootstraps\n",
    "\n",
    "# sample values from a normal distribution\n",
    "np.random.seed(123)\n",
    "data = norm(0, 1).rvs(m)\n",
    "\n",
    "# Compute bootstrap resamplings of data\n",
    "mu1_bootstrap = bootstrap(data, n,  np.std, kwargs=dict(axis=1, ddof=1))\n",
    "mu2_bootstrap = bootstrap(data, n, sigmaG, kwargs=dict(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the theoretical expectations for the two distributions\n",
    "x = np.linspace(0.8, 1.2, 1000)\n",
    "\n",
    "# error on the estimation of sigma from bootstrap\n",
    "sigma1 = 1. / np.sqrt(2 * (m - 1))\n",
    "pdf1 = norm(1, sigma1).pdf(x)\n",
    "\n",
    "# error on the estimation of sigma from bootstrap\n",
    "sigma2 = 1.06 / np.sqrt(m) \n",
    "pdf2 = norm(1, sigma2).pdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.hist(mu1_bootstrap, bins=50, density=True, histtype='step',\n",
    "        color='blue', ls='dashed', label=r'$\\sigma\\ {\\rm (std. dev.)}$')\n",
    "ax.plot(x, pdf1, color='gray')\n",
    "\n",
    "ax.hist(mu2_bootstrap, bins=50, density=True, histtype='step',\n",
    "        color='red', label=r'$\\sigma_G\\ {\\rm (quartile)}$')\n",
    "ax.plot(x, pdf2, color='gray')\n",
    "\n",
    "ax.set_xlim(0.82, 1.18)\n",
    "\n",
    "ax.set_xlabel(r'$\\sigma$', fontsize = 16)\n",
    "ax.set_ylabel(r'$p(\\sigma|x,I)$', fontsize = 16)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence estimation: Jackknife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroML.resample import jackknife\n",
    "from astroML.stats import sigmaG\n",
    "\n",
    "np.random.seed(123)\n",
    "m = 1000\n",
    "data = norm(0, 1).rvs(m)\n",
    "\n",
    "# Compute jackknife resampling\n",
    "\n",
    "# Standard deviation based\n",
    "mu_s, sigma_mu_s, mu_s_raw = jackknife(data, np.std,\n",
    "                                    kwargs=dict(axis=1, ddof=1),\n",
    "                                    return_raw_distribution=True)\n",
    "\n",
    "pdf1_theory = norm(1, 1. / np.sqrt(2 * (m - 1)))\n",
    "pdf1_jackknife = norm(mu_s, sigma_mu_s)\n",
    "\n",
    "# Sigma_G based\n",
    "mu_sigG, sigma_mu_sigG, mu_sigG_raw = jackknife(data, sigmaG,\n",
    "                                    kwargs=dict(axis=1),\n",
    "                                    return_raw_distribution=True)\n",
    "pdf2_theory = norm(data.std(), 1.06 / np.sqrt(m))\n",
    "pdf2_jackknife = norm(mu_sigG, sigma_mu_sigG)\n",
    "\n",
    "\n",
    "print(f\"mu_s = {mu_s:.3}, sigma_mu_s = {sigma_mu_s:.3}\")\n",
    "print(f\"mu_sigmaG = {mu_sigG:.3}, sigma_mu_sigmaG = {sigma_mu_sigG:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.subplots_adjust(left=0.11, right=0.95, bottom=0.2, top=0.9,\n",
    "                    wspace=0.25)\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.hist(mu_s_raw, np.linspace(0.996, 1.008, 100),\n",
    "        label=r'$\\sigma^*\\ {\\rm (std.\\ dev.)}$',\n",
    "        histtype='stepfilled', fc='white', ec='black', density=False)\n",
    "ax.hist(mu_sigG_raw, np.linspace(0.996, 1.008, 100),\n",
    "        label=r'$\\sigma_G^*\\ {\\rm (quartile)}$',\n",
    "        histtype='stepfilled', fc='gray', density=False)\n",
    "ax.legend(loc='upper left', handlelength=2, fontsize = 14)\n",
    "\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(0.004))\n",
    "ax.set_xlabel(r'$\\sigma^*$', fontsize = 14)\n",
    "ax.set_ylabel(r'$N(\\sigma^*)$', fontsize = 14)\n",
    "ax.set_xlim(0.998, 1.008)\n",
    "ax.set_ylim(0, 550)\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "x = np.linspace(0.45, 1.15, 1000)\n",
    "ax.plot(x, pdf1_jackknife.pdf(x),\n",
    "        color='blue', ls='dashed', label=r'$\\sigma\\ {\\rm (std.\\ dev.)}$',\n",
    "        zorder=2)\n",
    "ax.plot(x, pdf1_theory.pdf(x), color='gray', zorder=1)\n",
    "\n",
    "ax.plot(x, pdf2_jackknife.pdf(x),\n",
    "        color='red', label=r'$\\sigma_G\\ {\\rm (quartile)}$', zorder=2)\n",
    "ax.plot(x, pdf2_theory.pdf(x), color='gray', zorder=1)\n",
    "plt.legend(loc='upper left', handlelength=2, fontsize = 14)\n",
    "\n",
    "ax.set_xlabel(r'$\\sigma$', fontsize = 14)\n",
    "ax.set_ylabel(r'$p(\\sigma|x,I)$', fontsize = 14)\n",
    "ax.set_xlim(0.45, 1.15)\n",
    "ax.set_ylim(0, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This failure is a general problem with the standard jackknife method, which performs well for smooth differential statistics such as the mean and standard deviation, but does not perform well for medians, quantiles, and other rank-based statistics. For these sorts of statistics, a jackknife implementation that removes more than one observation can overcome this problem. The reason for this failure becomes apparent upon examination of the figure above: for $\\sigma_G$, the vast majority of jackknife samples yield one of three discrete values! Because quartiles are insensitive to the removal of outliers, all samples created by the removal of a point larger than $q_{75}$ lead to precisely the same estimate. The same is true for removal of any point smaller than $q_{25}$, and for any point in the range $q_{25} < x < q_{75}$. Because of this, the jackknife cannot accurately sample the error distribution, which leads to a gross misestimate of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convinient functions in astropy\n",
    "\n",
    "from astropy.stats import jackknife_stats\n",
    "\n",
    "x = np.random.normal(loc=0, scale=1, size=1000)\n",
    "estimate, bias, stderr, conf_interval = jackknife_stats(x, np.std)\n",
    "print(estimate , stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejecting a null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We flip a coin eight times and get six tails; should we reject the hypothesis that the coin is fair? We will assume the null hypothesis that the coin is indeed fair. Recall that we can find probabilities of coin flips with the binomial distribution,\n",
    "\n",
    "$$ p(k|b,N) = \\frac{N!}{k!(N-k)!} b^k (1-b)^{N-k}. $$\n",
    "\n",
    "Since p-values are defined as the probability that something *at least* as extreme as your data could have occurred (assuming the null hypothesis is correct), we can find the p-value by adding the probability of 6/8, 7/8, and 8/8 tails.\n",
    "\n",
    "$$ \\frac{8!}{6!2!}\\frac{1}{2}^6 \\frac{1}{2}^2 + \\frac{8!}{7!1!}\\frac{1}{2}^7 \\frac{1}{2}^1 + \\frac{8!}{8!0!}\\frac{1}{2}^8 \\frac{1}{2}^0$$\n",
    "\n",
    "We get that the probability of this occurring is 0.145; thus, we cannot reject the null hypothesis at the 0.05 significance level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example in class. \n",
    "\n",
    "Assume that $h_B(x) = \\mathcal{N} (\\mu = 100, \\sigma = 10) $ and $h_s(x) = \\mathcal{N} (\\mu = 150, \\sigma = 12)$, with $a$ = 0.1 and $N = 10^6$ (this will be image with 1000 x 1000 resolution elements; the $x$ values correspond to the sum of background and source counts). We will plot these two distributions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and draw the curves\n",
    "x = np.linspace(50, 200, 1000)\n",
    "p1 = 0.9 * norm(100, 10).pdf(x)\n",
    "p2 = 0.1 * norm(150, 12).pdf(x)\n",
    "\n",
    "# plot the distributions\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "ax.fill(x, p1, ec='k', fc='#AAAAAA', alpha=0.5)\n",
    "ax.fill(x, p2, '-k', fc='#AAAAAA', alpha=0.5)\n",
    "\n",
    "# plot x_c = 120\n",
    "ax.plot([120, 120], [0.0, 0.04], '--k')\n",
    "\n",
    "ax.text(100, 0.036, r'$h_B(x)$', ha='center', va='bottom', fontsize = 14)\n",
    "ax.text(150, 0.0035, r'$h_S(x)$', ha='center', va='bottom', fontsize = 14)\n",
    "ax.text(122, 0.039, r'$x_c=120$', ha='left', va='top', fontsize = 14)\n",
    "ax.text(125, 0.01, r'$(x > x_c\\ {\\rm classified\\ as\\ sources})$', fontsize = 14)\n",
    "\n",
    "ax.set_xlim(50, 200)\n",
    "ax.set_ylim(0, 0.04)\n",
    "\n",
    "ax.set_xlabel('$x$', fontsize = 14)\n",
    "ax.set_ylabel('$p(x)$', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we naively choose $x_c$=120 (a \"$2\\sigma$ cut” away from the mean for $h_B$, corresponding to a Type I error probability of $\\alpha$ = 0.024 ((1-95.45\\%)/2), **21,600 values will be incorrectly classified as a source!** The sample completeness for this value of $x_c$ is 0.994 and **99,400 values are correctly classified as a source.** Although the Type I error rate is only 0.024, the sample contamination is 21,600/(21,600+99,400) = 0.179, or over 7 times higher!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of distributions: KS-tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.step(np.sort(stats.norm.rvs(0,3,25)), np.linspace(0, 1, 25) ,lw = 3)\n",
    "plt.plot(np.sort(stats.norm.rvs(0,3,1000)), np.linspace(0, 1, 1000), lw=3)\n",
    "\n",
    "plt.annotate(\"\", xy=(2.3, 0.965), xytext=(2.3, 0.77),\n",
    "            arrowprops=dict(arrowstyle=\"<->\",lw=2))\n",
    "\n",
    "plt.text(2.6,0.86, \"D\", fontsize = 20)\n",
    "\n",
    "plt.legend(['CDF 1', 'CDF 2'])\n",
    "plt.title('Comparing CDFs for K-S test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "vals = np.random.normal(loc=0, scale=1, size= 1000)\n",
    "\n",
    "print(f'Normal: {stats.kstest(vals, \"norm\")}')\n",
    "print(f'Uniform: {stats.kstest(vals, \"uniform\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "sample1 = np.random.uniform(low=0.0, high=1.0,size=100)\n",
    "sample2 = np.random.normal(loc=0.0, scale=1.0,size=110)\n",
    "sample3 = np.random.normal(loc=0.0, scale=1.0,size=95)\n",
    "\n",
    "print(f'Uniform vs. Normal: {stats.ks_2samp(sample1, sample2)}')\n",
    "print(f'Normal vs. Normal: {stats.ks_2samp(sample2, sample3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll show an example using `scipy.stats.kstwo`, which performs the two-sided test statistic distribution. Similarly to other `scipy.stats` classes, we can calculate the first four moments using `kstwo.stats`. Additionally, we can compare the histogram of random samples generated using `kstwo.rvs` to the pdf using `kstwo.pdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstwo\n",
    "\n",
    "# Calculate the first four moments for a given n\n",
    "n = 500\n",
    "mean, var, skew, kurt = kstwo.stats(n, moments='mvsk')\n",
    "\n",
    "#Generate random values\n",
    "r = kstwo.rvs(n, size=1000)\n",
    "\n",
    "#Plot the ksone pdf and histogram\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "x = np.linspace(kstwo.ppf(0.01, n), kstwo.ppf(0.99, n), 100)\n",
    "plt.hist(r, density=True, bins='auto', histtype='stepfilled', alpha = 0.5, label = 'kstwo hist')\n",
    "plt.plot(x, kstwo.pdf(x, n),label='kstwo pdf')\n",
    "plt.xlim([x[0], x[-1]])\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check out many of the other tests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astr340",
   "language": "python",
   "name": "astr340"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
